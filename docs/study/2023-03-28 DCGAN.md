---
layout: default
title: DCGAN
nav_order: 6
parent: 논문 구현(Deep Learning)
---

# DCGAN
{: .no_toc}

## Table of contents
{: .no_toc .text-delta}

참고 논문 : [DCGAN.pdf](https://github.com/KimSungHeon/KimSungHeon.github.io/files/11085950/DCGAN.pdf)

구현 환경 : UBUNTU, Jupyterlab



**Model.py**
<script src="https://gist.github.com/KimSungHeon/f4d7ebbd0d5924987d18d044be005ed1.js"></script>
model.py 안에 들어있는 Discriminator와 Generator 클래스, 가중치 초기화 함수

  Vanilla Gan과 다른 점은 판별자(Discriminator)와 생성자(Generator) architecture가 Convolution Block들로 이루어져 있다는 것이다.
  이외에는 Original Gan과 동일하다.
  
  
**Main**
<script src="https://gist.github.com/KimSungHeon/cbd4cc8d9ddd14a22bee330087aa9ef4.js"></script>

사용한 dataset : http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html celebA Dataset

<script src="https://gist.github.com/KimSungHeon/00abd1aa52aa9f3194bcfd91f568825b.js"></script>

Hyperparameters:
  
  1) IMAGE_SIZE : 이미지의 크기, 높이와 너비가 같은 정사각형
  2) IMAGE_CHANNEL : 이미지의 채널, 흑백사진일 경우 - 1, 컬러이미지일 경우 - 3 
  3) Z_DIM : generator의 입력 랜덤 노이즈 벡터의 차원
  4) HIDDEN_DIM : generator와 discriminator 내부의 Deep Convolutional Layer 에 쓰일 은닉 유닛의 갯수
  5) BATCH_SIZE : 배치 크기
  6) LEARNING_RATE : 학습률
  7) BETA1 : Adam 최적화 사용 시 쓰일 hyperparameter 
        
   - PyTorch Document: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#adam
   - Paper : [ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION.6980.pdf](https://github.com/KimSungHeon/KimSungHeon.github.io/files/11086071/ADAM.A.METHOD.FOR.STOCHASTIC.OPTIMIZATION.6980.pdf)
  
  8) NUM_EPORHC : 수행할 epoch 전체 횟수

<script src="https://gist.github.com/KimSungHeon/d0b266e9ca8735c5ed8f098ed990a993.js"></script>

<script src="https://gist.github.com/KimSungHeon/6577e0cf373741859fb71864f2e90fa9.js"></script>

<script src="https://gist.github.com/KimSungHeon/4f3aa8641d736da268c9ab679f408e1e.js"></script>
  
<script src="https://gist.github.com/KimSungHeon/5afcf687e8fb612d66d6e50374829770.js"></script>
